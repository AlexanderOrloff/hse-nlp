{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По традиции начинаем с вопроса....\n",
    "\n",
    "У нас есть множество различных новостных статей на абсолютно разные темы. Нам нужно определить тему статьи (узкую) (найти в массе из 3000+ знаков какие-то самые значимые для этой статьи слова, которые делают её отличной от других статей и которые могут поступить в заголовок и составлять её  краткий пересказ) --- как нам это сделать? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидным образом, не все слова were created equal. Мы уже знакомы с рядос стоп слов, которые мы в лингвистике яростно выбрасываем из предложения, однако, и другие слова в тексте неравнознчны......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF_IDF\n",
    "\n",
    "Что это? И зачем оно нужно? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, это метрика, которая показывает насколько важно/релевантно слово в заданном документе. используется для анализа темы и в поисковиках.\n",
    "\n",
    "В этом семинаре мы попытаемся создать с помощью неё наш собственный поисковик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что нам на вход в поисковике поступило 'a brown cow'. У нас в мировой паутине лежит куча-куча-куча документов с множеством различных слов. Как по заданным словам понять, какой из них релевантнее? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # если нет pandas - не страшно - он тут для красоты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inquery = 'the brown cows'\n",
    "\n",
    "documentA = 'the black man went out at night for a stroll past the brown cows he owned He also noticed a wolf on the stroll but did not pay attention ...'\n",
    "documentB = 'The brown children sat around the fire and sang the songs ...'\n",
    "documentC = 'Everything about brown cows.  Brown cows live in a harsh enviroment ... '\n",
    "documentD = 'Everything about cows. Cows live in different enviroments ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы можем, не залезая в семантику, узнать, какой текст выдать первым?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf\n",
    "\n",
    "\n",
    "idf\n",
    "\n",
    "\n",
    "term frequency–inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avorl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "bagOfWordsA = nltk.word_tokenize(documentA.lower())\n",
    "bagOfWordsB = nltk.word_tokenize(documentB.lower())\n",
    "bagOfWordsC = nltk.word_tokenize(documentC.lower())\n",
    "bagOfWordsD = nltk.word_tokenize(documentD.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB)).union(set(bagOfWordsC)).union(set(bagOfWordsD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '...',\n",
       " 'a',\n",
       " 'about',\n",
       " 'also',\n",
       " 'and',\n",
       " 'around',\n",
       " 'at',\n",
       " 'attention',\n",
       " 'black',\n",
       " 'brown',\n",
       " 'but',\n",
       " 'children',\n",
       " 'cows',\n",
       " 'did',\n",
       " 'different',\n",
       " 'enviroment',\n",
       " 'enviroments',\n",
       " 'everything',\n",
       " 'fire',\n",
       " 'for',\n",
       " 'harsh',\n",
       " 'he',\n",
       " 'in',\n",
       " 'live',\n",
       " 'man',\n",
       " 'night',\n",
       " 'not',\n",
       " 'noticed',\n",
       " 'on',\n",
       " 'out',\n",
       " 'owned',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'sang',\n",
       " 'sat',\n",
       " 'songs',\n",
       " 'stroll',\n",
       " 'the',\n",
       " 'went',\n",
       " 'wolf'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsB:\n",
    "    numOfWordsB[word] += 1\n",
    "    \n",
    "numOfWordsC = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsC:\n",
    "    numOfWordsC[word] += 1\n",
    "    \n",
    "numOfWordsD = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsD:\n",
    "    numOfWordsD[word] += 1\n",
    "    \n",
    "df = pd.DataFrame([numOfWordsA, numOfWordsB,numOfWordsC, numOfWordsD ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>in</th>\n",
       "      <th>on</th>\n",
       "      <th>harsh</th>\n",
       "      <th>sang</th>\n",
       "      <th>the</th>\n",
       "      <th>enviroment</th>\n",
       "      <th>stroll</th>\n",
       "      <th>did</th>\n",
       "      <th>...</th>\n",
       "      <th>live</th>\n",
       "      <th>but</th>\n",
       "      <th>a</th>\n",
       "      <th>fire</th>\n",
       "      <th>not</th>\n",
       "      <th>also</th>\n",
       "      <th>he</th>\n",
       "      <th>brown</th>\n",
       "      <th>night</th>\n",
       "      <th>at</th>\n",
       "      <th>sat</th>\n",
       "      <th>children</th>\n",
       "      <th>cows</th>\n",
       "      <th>noticed</th>\n",
       "      <th>songs</th>\n",
       "      <th>out</th>\n",
       "      <th>owned</th>\n",
       "      <th>enviroments</th>\n",
       "      <th>wolf</th>\n",
       "      <th>different</th>\n",
       "      <th>pay</th>\n",
       "      <th>man</th>\n",
       "      <th>and</th>\n",
       "      <th>went</th>\n",
       "      <th>past</th>\n",
       "      <th>for</th>\n",
       "      <th>everything</th>\n",
       "      <th>around</th>\n",
       "      <th>attention</th>\n",
       "      <th>black</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  in  on  harsh  sang  the  enviroment  stroll  did  ...  live  but  \\\n",
       "0      0   0   1      0     0    3           0       2    1    1     0    1   \n",
       "1      0   0   0      0     1    3           0       0    0    1     0    0   \n",
       "2      1   1   0      1     0    0           1       0    0    1     1    0   \n",
       "3      1   1   0      0     0    0           0       0    0    1     1    0   \n",
       "\n",
       "   a  fire  not  also  he  brown  night  at  sat  children  cows  noticed  \\\n",
       "0  2     0    1     1   2      1      1   1    0         0     1        1   \n",
       "1  0     1    0     0   0      1      0   0    1         1     0        0   \n",
       "2  1     0    0     0   0      2      0   0    0         0     2        0   \n",
       "3  0     0    0     0   0      0      0   0    0         0     2        0   \n",
       "\n",
       "   songs  out  owned  enviroments  wolf  different  pay  man  and  went  past  \\\n",
       "0      0    1      1            0     1          0    1    1    0     1     1   \n",
       "1      1    0      0            0     0          0    0    0    1     0     0   \n",
       "2      0    0      0            0     0          0    0    0    0     0     0   \n",
       "3      0    0      0            1     0          1    0    0    0     0     0   \n",
       "\n",
       "   for  everything  around  attention  black  .  \n",
       "0    1           0       0          1      1  0  \n",
       "1    0           0       1          0      0  0  \n",
       "2    0           1       0          0      0  1  \n",
       "3    0           1       0          0      0  1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему иногда всё же но стоит выкидывать стоп-слова - предлоги, артикли и союзы?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## давайте построим свой tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf --- term frequency. В самом первом упрощении - это то, сколько раз слово встретилось в тексте (чем чаще искомое слово встретилось в заданном тексте по сравнению с другими, тем этот текст релевантнее запросу), в чём тут проблема? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому есть всякие adjustments. Так часто tf слова в документе считается как количество раз, когда оно появилось в этом документе, деленное на общее число слов документе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    #напишите функцию, которая получает на ввход bagofwords и numOfWords, а возвращает словарь с tf-ами для каждого слова из numofwords\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)\n",
    "tfC = computeTF(numOfWordsC, bagOfWordsC)\n",
    "tfD = computeTF(numOfWordsD, bagOfWordsD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 0.0,\n",
       " 'in': 0.0,\n",
       " 'on': 0.0,\n",
       " 'harsh': 0.0,\n",
       " 'sang': 0.08333333333333333,\n",
       " 'the': 0.25,\n",
       " 'enviroment': 0.0,\n",
       " 'stroll': 0.0,\n",
       " 'did': 0.0,\n",
       " '...': 0.08333333333333333,\n",
       " 'live': 0.0,\n",
       " 'but': 0.0,\n",
       " 'a': 0.0,\n",
       " 'fire': 0.08333333333333333,\n",
       " 'not': 0.0,\n",
       " 'also': 0.0,\n",
       " 'he': 0.0,\n",
       " 'brown': 0.08333333333333333,\n",
       " 'night': 0.0,\n",
       " 'at': 0.0,\n",
       " 'sat': 0.08333333333333333,\n",
       " 'children': 0.08333333333333333,\n",
       " 'cows': 0.0,\n",
       " 'noticed': 0.0,\n",
       " 'songs': 0.08333333333333333,\n",
       " 'out': 0.0,\n",
       " 'owned': 0.0,\n",
       " 'enviroments': 0.0,\n",
       " 'wolf': 0.0,\n",
       " 'different': 0.0,\n",
       " 'pay': 0.0,\n",
       " 'man': 0.0,\n",
       " 'and': 0.08333333333333333,\n",
       " 'went': 0.0,\n",
       " 'past': 0.0,\n",
       " 'for': 0.0,\n",
       " 'everything': 0.0,\n",
       " 'around': 0.08333333333333333,\n",
       " 'attention': 0.0,\n",
       " 'black': 0.0,\n",
       " '.': 0.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idf --- The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def computeIDF(documents):\n",
    "    #для того, чтобы посчитать idf надо подать все документы в функцию сразу \n",
    "    #напишите функцию, считающую idf для каждого слова - на входе массив из numOfWords для всех текстов \n",
    "    #на выходе словарь для слов \n",
    "    #см. ввод и вывод ниже\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents: # \n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsB, numOfWordsC, numOfWordsD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 0.6931471805599453,\n",
       " 'in': 0.6931471805599453,\n",
       " 'on': 1.3862943611198906,\n",
       " 'harsh': 1.3862943611198906,\n",
       " 'sang': 1.3862943611198906,\n",
       " 'the': 0.6931471805599453,\n",
       " 'enviroment': 1.3862943611198906,\n",
       " 'stroll': 1.3862943611198906,\n",
       " 'did': 1.3862943611198906,\n",
       " '...': 0.0,\n",
       " 'live': 0.6931471805599453,\n",
       " 'but': 1.3862943611198906,\n",
       " 'a': 0.6931471805599453,\n",
       " 'fire': 1.3862943611198906,\n",
       " 'not': 1.3862943611198906,\n",
       " 'also': 1.3862943611198906,\n",
       " 'he': 1.3862943611198906,\n",
       " 'brown': 0.28768207245178085,\n",
       " 'night': 1.3862943611198906,\n",
       " 'at': 1.3862943611198906,\n",
       " 'sat': 1.3862943611198906,\n",
       " 'children': 1.3862943611198906,\n",
       " 'cows': 0.28768207245178085,\n",
       " 'noticed': 1.3862943611198906,\n",
       " 'songs': 1.3862943611198906,\n",
       " 'out': 1.3862943611198906,\n",
       " 'owned': 1.3862943611198906,\n",
       " 'enviroments': 1.3862943611198906,\n",
       " 'wolf': 1.3862943611198906,\n",
       " 'different': 1.3862943611198906,\n",
       " 'pay': 1.3862943611198906,\n",
       " 'man': 1.3862943611198906,\n",
       " 'and': 1.3862943611198906,\n",
       " 'went': 1.3862943611198906,\n",
       " 'past': 1.3862943611198906,\n",
       " 'for': 1.3862943611198906,\n",
       " 'everything': 0.6931471805599453,\n",
       " 'around': 1.3862943611198906,\n",
       " 'attention': 1.3862943611198906,\n",
       " 'black': 1.3862943611198906,\n",
       " '.': 0.6931471805599453}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf_idf  целиком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тф_айдф для слова в документе - это просто произведение его тф в документе на его идф"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    #давайте\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "tfidfC = computeTFIDF(tfC, idfs)\n",
    "tfidfD = computeTFIDF(tfD, idfs)\n",
    "df = pd.DataFrame([tfidfA, tfidfB, tfidfC, tfidfD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>in</th>\n",
       "      <th>on</th>\n",
       "      <th>harsh</th>\n",
       "      <th>sang</th>\n",
       "      <th>the</th>\n",
       "      <th>enviroment</th>\n",
       "      <th>stroll</th>\n",
       "      <th>did</th>\n",
       "      <th>...</th>\n",
       "      <th>live</th>\n",
       "      <th>but</th>\n",
       "      <th>a</th>\n",
       "      <th>fire</th>\n",
       "      <th>not</th>\n",
       "      <th>also</th>\n",
       "      <th>he</th>\n",
       "      <th>brown</th>\n",
       "      <th>night</th>\n",
       "      <th>at</th>\n",
       "      <th>sat</th>\n",
       "      <th>children</th>\n",
       "      <th>cows</th>\n",
       "      <th>noticed</th>\n",
       "      <th>songs</th>\n",
       "      <th>out</th>\n",
       "      <th>owned</th>\n",
       "      <th>enviroments</th>\n",
       "      <th>wolf</th>\n",
       "      <th>different</th>\n",
       "      <th>pay</th>\n",
       "      <th>man</th>\n",
       "      <th>and</th>\n",
       "      <th>went</th>\n",
       "      <th>past</th>\n",
       "      <th>for</th>\n",
       "      <th>everything</th>\n",
       "      <th>around</th>\n",
       "      <th>attention</th>\n",
       "      <th>black</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.023974</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.106638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106638</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.044259</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044259</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.053319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057536</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.069315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      about        in       on     harsh      sang       the  enviroment  \\\n",
       "0  0.000000  0.000000  0.04621  0.000000  0.000000  0.069315    0.000000   \n",
       "1  0.000000  0.000000  0.00000  0.000000  0.115525  0.173287    0.000000   \n",
       "2  0.053319  0.053319  0.00000  0.106638  0.000000  0.000000    0.106638   \n",
       "3  0.069315  0.069315  0.00000  0.000000  0.000000  0.000000    0.000000   \n",
       "\n",
       "    stroll      did  ...      live      but         a      fire      not  \\\n",
       "0  0.09242  0.04621  0.0  0.000000  0.04621  0.046210  0.000000  0.04621   \n",
       "1  0.00000  0.00000  0.0  0.000000  0.00000  0.000000  0.115525  0.00000   \n",
       "2  0.00000  0.00000  0.0  0.053319  0.00000  0.053319  0.000000  0.00000   \n",
       "3  0.00000  0.00000  0.0  0.069315  0.00000  0.000000  0.000000  0.00000   \n",
       "\n",
       "      also       he     brown    night       at       sat  children      cows  \\\n",
       "0  0.04621  0.09242  0.009589  0.04621  0.04621  0.000000  0.000000  0.009589   \n",
       "1  0.00000  0.00000  0.023974  0.00000  0.00000  0.115525  0.115525  0.000000   \n",
       "2  0.00000  0.00000  0.044259  0.00000  0.00000  0.000000  0.000000  0.044259   \n",
       "3  0.00000  0.00000  0.000000  0.00000  0.00000  0.000000  0.000000  0.057536   \n",
       "\n",
       "   noticed     songs      out    owned  enviroments     wolf  different  \\\n",
       "0  0.04621  0.000000  0.04621  0.04621     0.000000  0.04621   0.000000   \n",
       "1  0.00000  0.115525  0.00000  0.00000     0.000000  0.00000   0.000000   \n",
       "2  0.00000  0.000000  0.00000  0.00000     0.000000  0.00000   0.000000   \n",
       "3  0.00000  0.000000  0.00000  0.00000     0.138629  0.00000   0.138629   \n",
       "\n",
       "       pay      man       and     went     past      for  everything  \\\n",
       "0  0.04621  0.04621  0.000000  0.04621  0.04621  0.04621    0.000000   \n",
       "1  0.00000  0.00000  0.115525  0.00000  0.00000  0.00000    0.000000   \n",
       "2  0.00000  0.00000  0.000000  0.00000  0.00000  0.00000    0.053319   \n",
       "3  0.00000  0.00000  0.000000  0.00000  0.00000  0.00000    0.069315   \n",
       "\n",
       "     around  attention    black         .  \n",
       "0  0.000000    0.04621  0.04621  0.000000  \n",
       "1  0.115525    0.00000  0.00000  0.000000  \n",
       "2  0.000000    0.00000  0.00000  0.053319  \n",
       "3  0.000000    0.00000  0.00000  0.069315  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим на brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA, documentB, documentC, documentD])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>also</th>\n",
       "      <th>and</th>\n",
       "      <th>around</th>\n",
       "      <th>at</th>\n",
       "      <th>attention</th>\n",
       "      <th>black</th>\n",
       "      <th>brown</th>\n",
       "      <th>but</th>\n",
       "      <th>children</th>\n",
       "      <th>cows</th>\n",
       "      <th>did</th>\n",
       "      <th>different</th>\n",
       "      <th>enviroment</th>\n",
       "      <th>enviroments</th>\n",
       "      <th>everything</th>\n",
       "      <th>fire</th>\n",
       "      <th>for</th>\n",
       "      <th>harsh</th>\n",
       "      <th>he</th>\n",
       "      <th>in</th>\n",
       "      <th>live</th>\n",
       "      <th>man</th>\n",
       "      <th>night</th>\n",
       "      <th>not</th>\n",
       "      <th>noticed</th>\n",
       "      <th>on</th>\n",
       "      <th>out</th>\n",
       "      <th>owned</th>\n",
       "      <th>past</th>\n",
       "      <th>pay</th>\n",
       "      <th>sang</th>\n",
       "      <th>sat</th>\n",
       "      <th>songs</th>\n",
       "      <th>stroll</th>\n",
       "      <th>the</th>\n",
       "      <th>went</th>\n",
       "      <th>wolf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351315</td>\n",
       "      <td>0.415471</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.175657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283285</td>\n",
       "      <td>0.283285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404358</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      about      also       and    around        at  attention     black  \\\n",
       "0  0.000000  0.175657  0.000000  0.000000  0.175657   0.175657  0.175657   \n",
       "1  0.000000  0.000000  0.277331  0.277331  0.000000   0.000000  0.000000   \n",
       "2  0.283285  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "3  0.318800  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "\n",
       "      brown       but  children      cows       did  different  enviroment  \\\n",
       "0  0.112120  0.175657  0.000000  0.112120  0.175657   0.000000    0.000000   \n",
       "1  0.177017  0.000000  0.277331  0.000000  0.000000   0.000000    0.000000   \n",
       "2  0.458688  0.000000  0.000000  0.458688  0.000000   0.000000    0.359311   \n",
       "3  0.000000  0.000000  0.000000  0.516193  0.000000   0.404358    0.000000   \n",
       "\n",
       "   enviroments  everything      fire       for     harsh        he        in  \\\n",
       "0     0.000000    0.000000  0.000000  0.175657  0.000000  0.351315  0.000000   \n",
       "1     0.000000    0.000000  0.277331  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000    0.283285  0.000000  0.000000  0.359311  0.000000  0.283285   \n",
       "3     0.404358    0.318800  0.000000  0.000000  0.000000  0.000000  0.318800   \n",
       "\n",
       "       live       man     night       not   noticed        on       out  \\\n",
       "0  0.000000  0.175657  0.175657  0.175657  0.175657  0.175657  0.175657   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.283285  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.318800  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      owned      past       pay      sang       sat     songs    stroll  \\\n",
       "0  0.175657  0.175657  0.175657  0.000000  0.000000  0.000000  0.351315   \n",
       "1  0.000000  0.000000  0.000000  0.277331  0.277331  0.277331  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        the      went      wolf  \n",
       "0  0.415471  0.175657  0.175657  \n",
       "1  0.655954  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь даваайте создадим наш парсер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymorphy2\n",
    "import string\n",
    "import re\n",
    "from math import log\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "vectorizer1 = CountVectorizer(binary = True)\n",
    "vectorizertf = TfidfVectorizer(use_idf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['', 'question1', 'question2', 'is_duplicate']\n",
    "\n",
    "['0', 'Какова история кохинор кох-и-ноор-бриллиант', 'что произойдет, если правительство Индии украдет кохинор кох-и-ноор-алмаз назад', '0']\n",
    "\n",
    "['1', 'как я могу увеличить скорость моего интернет-соединения, используя vpn', 'как повысить скорость интернета путем взлома через dns', '0']\n",
    "\n",
    "['2', 'почему я мысленно очень одинок, как я могу это решить', 'найти остаток, когда математика 23 ^ 24 математика разделена на 24 23', '0']\n",
    "\n",
    "['3', 'которые растворяют в воде быстро сахарную соль метан и углеродный диоксид', 'какая рыба выживет в соленой воде', '0']\n",
    "\n",
    "['4', 'астрология: я - луна-колпачок из козерога и крышка, поднимающая то, что это говорит обо мне', 'Я тройная луна-козерог и восхождение в козероге, что это говорит обо мне', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте обработаем только  20 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(): # возвращаем [corpus, inquiery, lenghths, scores, normal]\n",
    "    corpus = [] #сюда кладём тексты из [2] столбца, где каждое слово прошло препроцессинг\n",
    "                #(нижний регистр, нет знаков препинания) и каждое слово в начальной форме\n",
    "    inquiery = [] #сюда кладём тексты из [1] столбца - их препроцесить не надо\n",
    "    #lenghths = []\n",
    "    scores = [] #сюда кладём информацию из [3] -- является ли ответ соответсвующим вопросу\n",
    "    normal = []\n",
    "\n",
    "    with open('quora_question_pairs_rus.csv', encoding = 'utf-8') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            # отсюда убрать\n",
    "            normal.append(row[2])\n",
    "            text = preproc(row[2])\n",
    "            corpus.append(text)\n",
    "            inquiery.append(row[1])\n",
    "            #lenghths.append(len(text.split(' ')))\n",
    "            scores.append(row[3])\n",
    "            if len(scores) == 20000: #оч плохо\n",
    "                #return [corpus, inquiery, lenghths, scores, normal]\n",
    "                return [corpus, inquiery, scores, normal]\n",
    "\n",
    "def preproc(data):                      # препроцессинг (убираем знаки препинания и числа, приводим всё к начальной форме)\n",
    "            data = data.split()        \n",
    "            text = ''                   # числа есть только в тех информации, в самом скрипте все числа пишутся буквами\n",
    "            for word in data:\n",
    "                word = word.strip('[!,.?\"]')\n",
    "                p = morph.parse(word.strip())[0]\n",
    "                p = p.normal_form\n",
    "                if p != '-':\n",
    "                    if re.search(r'\\d', p) == None:\n",
    "                        text  = text + ' ' + p\n",
    "            return text[1:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_texts, inquiery_texts, scores, normal_texts =  data[0][1:], data[1][1:], data[2][1:], data[3][1:]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['что произойти если правительство индия украсть кохинор кох-и-ноор-алмаз назад', 'как повысить скорость интернет путём взлом через dns', 'найти остаток когда математик ^ математик разделить на', 'какой рыба выжить в солёный вода', 'я тройной луна-козерог и восхождение в козерог что это говорить о я']\n",
      "['Какова история кохинор кох-и-ноор-бриллиант', 'как я могу увеличить скорость моего интернет-соединения, используя vpn', 'почему я мысленно очень одинок, как я могу это решить', 'которые растворяют в воде быстро сахарную соль метан и углеродный диоксид', 'астрология: я - луна-колпачок из козерога и крышка, поднимающая то, что это говорит обо мне']\n",
      "['0', '0', '0', '0', '1']\n"
     ]
    }
   ],
   "source": [
    "print(corpus_texts[:5])\n",
    "print(inquiery_texts[:5])\n",
    "print(scores[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_matrix1 = vectorizer1.fit_transform(corpus_texts)\n",
    "voc = vectorizer1.get_feature_names() #получили вокабуляр -- какие вообще есть слова, у каждого еще и свой индекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = vectorizertf.fit_transform(corpus_texts)\n",
    "tf = tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_mat( inquiery, voc):\n",
    "    #делаем препроцессинг инквери\n",
    "    inq = preproc(inquiery)\n",
    "    # создали вектор из нулей, равный нашему вакабуляру\n",
    "    vec = np.zeros((len(voc)))\n",
    "    for word in inq.split(' '):\n",
    "        if word in voc:\n",
    "            index = voc.index(word)\n",
    "            vec[index] = 1 # нули начинают заполняться единицами\n",
    "    res = np.dot(tf,vec) #перемножили 2 вектора --- получили что?\n",
    "    \n",
    "    results = np.argsort(res)[::-1][:5]\n",
    "    \n",
    "   \n",
    "    for i in results:\n",
    "        print(normal_texts[i])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как работает правительство Индии\n",
      "почему правительство Индии запрещает все\n",
      "какая разница между парламентом и правительством Индии\n",
      "есть ли квота в Индии в Индии?\n",
      "каковы преимущества решения правительства Индии о вывозе 500 и 1000 рупий\n"
     ]
    }
   ],
   "source": [
    "search_mat('правительство индии',voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
