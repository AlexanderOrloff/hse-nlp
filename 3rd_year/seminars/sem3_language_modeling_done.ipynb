{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7c0vMPN8gWE"
      },
      "source": [
        "Некоторые задания в этой тетрадки были созданы на основе соотвествующей тетрадки курса NLP от Elena Voita."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pjlNnOv4Ut4"
      },
      "source": [
        "# Генерация текста: н-граммы\n",
        "\n",
        "В этой тетрадке мы научимся делать простую модель генерации текста на основе н-грамм и встречаемости в корпусе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nlpXQYlpuwmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TcWFfFlLgb1r"
      },
      "outputs": [],
      "source": [
        "random.seed(1)\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WT4GhNjvba0"
      },
      "source": [
        "Будем пробовать генерировать шутки. Для обучения будем использовать [датасет с постами reddit](https://kaggle.com/datasets/thedevastator/one-million-reddit-jokes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2VJz6GMP1nNu"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/NLP Course Tutoring/datasets/reddit_jokes.csv'\n",
        "data = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "xDqSNS4s_tXc",
        "outputId": "24ea6fcf-2cce-4bff-c5bc-58e79465dd61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type      id subreddit.id subreddit.name  subreddit.nsfw  created_utc  \\\n",
              "0  post  ftbp1i        2qh72          jokes           False   1585785543   \n",
              "1  post  ftboup        2qh72          jokes           False   1585785522   \n",
              "2  post  ftbopj        2qh72          jokes           False   1585785508   \n",
              "3  post  ftbnxh        2qh72          jokes           False   1585785428   \n",
              "4  post  ftbjpg        2qh72          jokes           False   1585785009   \n",
              "\n",
              "                                           permalink      domain  url  \\\n",
              "0  https://old.reddit.com/r/Jokes/comments/ftbp1i...  self.jokes  NaN   \n",
              "1  https://old.reddit.com/r/Jokes/comments/ftboup...  self.jokes  NaN   \n",
              "2  https://old.reddit.com/r/Jokes/comments/ftbopj...  self.jokes  NaN   \n",
              "3  https://old.reddit.com/r/Jokes/comments/ftbnxh...  self.jokes  NaN   \n",
              "4  https://old.reddit.com/r/Jokes/comments/ftbjpg...  self.jokes  NaN   \n",
              "\n",
              "                                            selftext  \\\n",
              "0  My corona is covered with foreskin so it is no...   \n",
              "1                         It's called Google Sheets.   \n",
              "2  The vacuum doesn't snore after sex.\\r\\n\\r\\n&am...   \n",
              "3                                          [removed]   \n",
              "4                                          [removed]   \n",
              "\n",
              "                                               title  score  \n",
              "0               I am soooo glad I'm not circumcised!      2  \n",
              "1  Did you know Google now has a platform for rec...      9  \n",
              "2  What is the difference between my wife and my ...     15  \n",
              "3                              My last joke for now.      9  \n",
              "4              The Nintendo 64 turns 18 this week...    134  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b563455-7628-4afc-af41-17e6caafcdc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit.id</th>\n",
              "      <th>subreddit.name</th>\n",
              "      <th>subreddit.nsfw</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>permalink</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>selftext</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbp1i</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785543</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbp1i...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My corona is covered with foreskin so it is no...</td>\n",
              "      <td>I am soooo glad I'm not circumcised!</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>post</td>\n",
              "      <td>ftboup</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785522</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftboup...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It's called Google Sheets.</td>\n",
              "      <td>Did you know Google now has a platform for rec...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbopj</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785508</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbopj...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The vacuum doesn't snore after sex.\\r\\n\\r\\n&amp;am...</td>\n",
              "      <td>What is the difference between my wife and my ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbnxh</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785428</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbnxh...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>My last joke for now.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbjpg</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785009</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbjpg...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>The Nintendo 64 turns 18 this week...</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b563455-7628-4afc-af41-17e6caafcdc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b563455-7628-4afc-af41-17e6caafcdc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b563455-7628-4afc-af41-17e6caafcdc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6542fc9c-d268-4090-9686-91f33575e1eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6542fc9c-d268-4090-9686-91f33575e1eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6542fc9c-d268-4090-9686-91f33575e1eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSHwGZ-S3t-a"
      },
      "source": [
        "Так как наша задача генерации требует только текста, оставим только соответствующий столбец."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Sg3r3lQI16CR"
      },
      "outputs": [],
      "source": [
        "columns = ['selftext']\n",
        "data = data[columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edTMfW2Z6lBP"
      },
      "source": [
        "## Обработка данных\n",
        "###1. Чистка датасета\n",
        "Для начала нужно определиться, есть в данных пропуски, и избавиться от них, если есть.\n",
        "\n",
        "__Подсказка:__ Часто пропуски они обозначаются как nan, но иногда можно заметить иные способы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "IhF_dtcpZ4-F",
        "outputId": "b1bab359-b9ac-41c8-849d-d62ea51e74f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "selftext\n",
              "[removed]                          232919\n",
              "[deleted]                          188442\n",
              "\\[removed\\]                           272\n",
              "To get to the other side.             125\n",
              "Dr. Dre                               111\n",
              "A stick.                               83\n",
              "None.                                  81\n",
              "A stick                                76\n",
              "He worked it out with a pencil.        74\n",
              "Then it hit me.                        72\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>selftext</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>[removed]</th>\n",
              "      <td>232919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[deleted]</th>\n",
              "      <td>188442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\[removed\\]</th>\n",
              "      <td>272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>To get to the other side.</th>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dr. Dre</th>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A stick.</th>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>None.</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A stick</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>He worked it out with a pencil.</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Then it hit me.</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data['selftext'].value_counts()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KdyZaYFZ4-H"
      },
      "source": [
        "Можно заметить, что наиболее частым классом являются _removed_ или _deleted_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alNSuLSPZ4-H",
        "outputId": "7d8bddfe-2469-4365-e8a4-5e2cfb469d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер данных до чистки (999998, 1)\n",
            "Размер данных после чистки (573847, 1)\n"
          ]
        }
      ],
      "source": [
        "print('Размер данных до чистки', data.shape)\n",
        "data = data[~data.isin(['[removed]', '[deleted]', '\\[removed\\]', 'removed', 'deleted'])]\n",
        "data = data.dropna()\n",
        "print('Размер данных после чистки', data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(100000)"
      ],
      "metadata": {
        "id": "Wmen9kMBbj07"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Z1N5z2Z4-I"
      },
      "source": [
        "Надо тексты привести к нижнему регистру и убрать пунктуацию.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы. При делении текста на слова, используйте word_tokenize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30WZnCmyZ4-I",
        "outputId": "6f975c00-f403-408f-fb76-df71743dbb98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ3V-peRAg3d"
      },
      "source": [
        "Надо тексты привести к нижнему регистру. Пунктуацию можно оставить, так как она влияет на смысл предложения и на встречаемость.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы. При делении текста на слова, используйте word_tokenize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7BN4LWOLZ4-I"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WoPyw7dvZ4-J"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zWzU9n0wZ4-J"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    '''\n",
        "    Делит текст на слова и пунктуацию и приводит все к нижнему регистру\n",
        "    :param text: строка\n",
        "    :returns: список слов и знаков препинания\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    new_text = []\n",
        "    for word in word_tokenize(text):\n",
        "        new_text.append(word)\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87tTCnhoZ4-J",
        "outputId": "3e664aeb-4e97-47e4-dc01-a74055a934ab",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100000/100000 [00:53<00:00, 1867.46it/s]\n",
            "100%|██████████| 100000/100000 [00:00<00:00, 768943.81it/s]\n"
          ]
        }
      ],
      "source": [
        "data['words'] = data['selftext'].progress_apply(clean_text)\n",
        "data['lens'] = data['words'].progress_apply(len)\n",
        "data = data[data.lens > 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YSTg92TiZ4-J"
      },
      "outputs": [],
      "source": [
        "words = data['words'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDY-l21aZ4-J",
        "outputId": "fd824094-549f-4655-8d03-a6843c83d1b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['but',\n",
              "  'recently',\n",
              "  'i',\n",
              "  \"'ve\",\n",
              "  'build',\n",
              "  'up',\n",
              "  'a',\n",
              "  'tolerance',\n",
              "  'to',\n",
              "  'it',\n",
              "  '.'],\n",
              " ['that', 'place', 'is', 'one', 'giant', 'pyramid', 'scheme', '!']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "words[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUp_9FzUW3Lu"
      },
      "source": [
        "## N-grams\n",
        "Для начала попробуем создать самую простую модель, основанную на встречаемости н-граммы в корпусе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mP00Mb3MlMeL"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EQQpVdxSBahu"
      },
      "outputs": [],
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS = '[bos]', '[eos]'\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, lines, n):\n",
        "        assert n >= 1\n",
        "        self.n = n\n",
        "        self.counts = self.ngram_counts(lines, self.n)\n",
        "\n",
        "        # перевести количества в вероятности\n",
        "        self.probs = defaultdict(Counter)\n",
        "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
        "\n",
        "        for key, value in self.counts.items():\n",
        "            sum_of_prefix = sum(value.values())\n",
        "            for word, cnts in value.items():\n",
        "                self.probs[key][word] = cnts / sum_of_prefix\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        \"\"\"\n",
        "        :param prefix: строка запроса\n",
        "        :returns: словарь с возможными продолжениями заданного префикса\n",
        "        \"\"\"\n",
        "        prefix = prefix.split()\n",
        "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
        "        prefix = [ BOS ] * (self.n - 1 - len(prefix)) + prefix\n",
        "        return self.probs[tuple(prefix)]\n",
        "\n",
        "    @staticmethod\n",
        "    def ngram_counts(lines, n):\n",
        "        dictionary = defaultdict(Counter)\n",
        "        for line in lines:\n",
        "            new_line = [BOS] * (n-1) + line + [EOS]\n",
        "            for i in range(n-1, len(new_line)):\n",
        "                prefix = tuple(new_line[i-n+1:i])\n",
        "                word = new_line[i]\n",
        "                dictionary[prefix][word] += 1\n",
        "        return dictionary\n",
        "\n",
        "# Проверим работу функции ngram_counts\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = NGramLanguageModel.ngram_counts(dummy_lines, n=3)\n",
        "# assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "# assert len(dummy_counts[(BOS, BOS)]) == 59\n",
        "# assert dummy_counts[BOS, 'a']['melon'] == 1\n",
        "\n",
        "# Проверим работу модели\n",
        "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
        "p_initial = dummy_lm.get_possible_next_tokens('')\n",
        "# assert p_initial.most_common(1)[0][0] == 'a'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vLe8Zhq4wMJZ"
      },
      "outputs": [],
      "source": [
        "lm = NGramLanguageModel(words, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOl9KlImvaLa"
      },
      "source": [
        "__Вопрос:__\n",
        "- видете ли вы, какие недочеты могут быть в такой версии модели?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUO1rc4Avxck"
      },
      "source": [
        "### Методы составления предложений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v96is9vGawaV"
      },
      "source": [
        "__1. Жадный метод__\n",
        "\n",
        "Берём самое часто встречаемое слово"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "y55QKTqUmgki"
      },
      "outputs": [],
      "source": [
        "def get_next_word_greedy(lm, prefix):\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    return lm.get_possible_next_tokens(prefix).most_common(1)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwHDk4aemgkx",
        "outputId": "534153bd-8173-4d8f-9ada-47a12f2780d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get off the plane . the man says , `` i 'm not sure if it 's a little bit of\n"
          ]
        }
      ],
      "source": [
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word_greedy(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh9oYWyosfnG",
        "outputId": "ad953e18-5e39-426e-8f7c-10954de7f807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i 'm not sure if it 's a little bit of a sudden , a man walks into a barbar \n"
          ]
        }
      ],
      "source": [
        "prefix = ''\n",
        "word = get_next_word_greedy(lm, prefix)\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word_greedy(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix + f'{word} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euWO6e9hTRkG"
      },
      "source": [
        "2. Выбор наиболее вероятного слова не показал хороших результатов. Тем более, он будет строить очень много похожих предложений, а нам хочется разнообразия. Давайте попробуем семплировать методом top-k: выбираем k наиболее встречаемых вариантов и из них выбираем один случайным образом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YlQNWIZrS-aK"
      },
      "outputs": [],
      "source": [
        "def get_next_word_topk(lm: NGramLanguageModel, prefix: str, k:int) -> str:\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :param k: количество слов в top-k\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    next_words = lm.get_possible_next_tokens(prefix).most_common(k)\n",
        "    index = random.randint(0, min(k, len(next_words))-1)\n",
        "    return next_words[index][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get_next_word_topk(lm, prefix, 5)"
      ],
      "metadata": {
        "id": "GM4kRYmOcr0Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUlsfNObToqk",
        "outputId": "5ee08f26-adf8-409c-a525-48e2715c0c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "want to have a wife . the first time i 'm not saying that they have been a bit . the\n"
          ]
        }
      ],
      "source": [
        "prefix = 'want'\n",
        "repeat = 20\n",
        "for i in range(repeat):\n",
        "    word = get_next_word_topk(lm, prefix, 5)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkBhxv88Ts0_",
        "outputId": "c75a16c1-e245-487b-f428-caea47390983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "because they have a good time for the next morning . [eos] \n"
          ]
        }
      ],
      "source": [
        "prefix = ''\n",
        "word = get_next_word_topk(lm, '', 5)\n",
        "while word != EOS:\n",
        "    prefix += f'{word} '\n",
        "    word = get_next_word_topk(lm, prefix, 5)\n",
        "print(prefix + f'{word} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC5axKpqtcvH"
      },
      "source": [
        "3. Для сравнения можно сделать beam search. Но это не самое приятное развлечени, поэтому мы этого делать не будем. Но если это надо, то это уже написано, например, в генеративных моделях библиотеки transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D71N55ESiJav"
      },
      "source": [
        "## Оценивание модели\n",
        "Раз мы научились делать простую языковую модель, надо понять, насколько она хорошо описывает язык. Для оценивания этого используем перплексию.\n",
        "\n",
        "$PPL(W) = 2^{log_{2}(P(W)^{-\\frac{1}{N}})} =2^{{-\\frac{1}{N}}log_{2}(P(W))}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['words'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVL1wzOJBEbE",
        "outputId": "430b40e7-e923-4c63-f707-bcf2f8221263"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86130,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vos4iA5mofJO"
      },
      "source": [
        "1. Для начала нужно разделить данные на тренировочные и тестовые"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PtnXGWswob2l"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(data['words'], train_size=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HDDyuiPonKy"
      },
      "source": [
        "2. Давайте напишем функцию, которая будет считать перплексию для каждого отдельного предложения на основе n-грамм. Для каждой нграммы считается её вероятность. Нам её считать не надо, так как она уже записана в атрибуте _self.probs_ в нашем классе модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wYUka8tVoqZU"
      },
      "outputs": [],
      "source": [
        "def perplexity(model: NGramLanguageModel, text: list, n=1) -> float:\n",
        "    \"\"\"\n",
        "    :param model: language model\n",
        "    :param text: список н-грамм предложения\n",
        "    :param n: количество слов в н-грамме\n",
        "    :returns: значение перплексии одного предложения\n",
        "    \"\"\"\n",
        "    result = 0\n",
        "    length = 0\n",
        "    for ngram in text:\n",
        "        if n == 1:\n",
        "            prefix = ()\n",
        "        else:\n",
        "            prefix = ngram[:n-1]\n",
        "        prob = model.probs[prefix][ngram[-1]]\n",
        "        if prob != 0:\n",
        "            result += np.log2(prob)\n",
        "        length += 1\n",
        "    enthropy = -(result / length)\n",
        "    return 2**enthropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtiVA2fWqAri"
      },
      "source": [
        "3. Теперь можем посчитать среднюю перплексию по всему датасету."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RLeSHLdAzWEM"
      },
      "outputs": [],
      "source": [
        "from nltk.util import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nbtX8nbqA_U",
        "outputId": "7049e6d6-4204-4f06-c4da-0cafa55f1430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1127.897092054018\n"
          ]
        }
      ],
      "source": [
        "n = 1\n",
        "lm = NGramLanguageModel(X_train, n=n)\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=n))\n",
        "    value = perplexity(lm, test_sent, n=n)\n",
        "    avg_ppl += value\n",
        "\n",
        "avg_ppl /=  len(X_test)\n",
        "# assert np.isclose(avg_ppl, 1857.90, atol=1e-1)\n",
        "print(avg_ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnNeiymmI0Yh"
      },
      "source": [
        "Попробуем теперь сравнить перплексию для моделей униграм, биграм и триграм. Почему результаты получились такие?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-HiheYengcQ",
        "outputId": "30ba7540-9a7a-408e-f20e-1e446ba99297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53.79759688020874\n"
          ]
        }
      ],
      "source": [
        "lm = NGramLanguageModel(X_train, n=2)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=2))\n",
        "    value = perplexity(lm, test_sent, 2)\n",
        "    all_ppls.append((' '.join(sentence), value))\n",
        "    avg_ppl += value\n",
        "print(avg_ppl / len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjTDqt9Dngcg",
        "outputId": "769e1a08-4791-48f4-ed11-c9361c72f3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('an anti-climactic climatic joke', 1.0) ('the information is groundbreaking', 3357.0038199694604)\n"
          ]
        }
      ],
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjUYqy8Ungch",
        "outputId": "aa8d6246-f68e-42cb-e95d-274e657e387f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.199512956583058\n"
          ]
        }
      ],
      "source": [
        "lm = NGramLanguageModel(X_train, n=3)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=3))\n",
        "    value = perplexity(lm, test_sent, 3)\n",
        "    all_ppls.append((' '.join(sentence), value))\n",
        "    avg_ppl += value\n",
        "print(avg_ppl / len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HEh_qm3ngch",
        "outputId": "66df3af8-ab57-4023-8b22-244572cbb161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('but men can fake love .', 1.0) ('to the dock !', 403.60128840230425)\n"
          ]
        }
      ],
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huzgWYb7nmlx"
      },
      "source": [
        "## Использование готовых инструментов\n",
        "К счастью, нам всё писать необязательно. Необходимые функции и модули уже были написаны умными программистами. Давайте посмотрим на модуль nltk и на то, что он нам предлагает."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "r8OKwq9ql94P"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "\n",
        "n = 1\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J32Wf2Km6Ew",
        "outputId": "2ffce224-7f2b-4a67-e5af-61033aa389ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "987.0364336249156\n"
          ]
        }
      ],
      "source": [
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "X_test_list = X_test.tolist()\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    value = model.perplexity(test)\n",
        "    all_ppls.append((' '.join(X_test_list[i]), value))\n",
        "    if value != np.inf:\n",
        "        avg_ppl += value\n",
        "print(avg_ppl / i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psvTMTHfnUMX"
      },
      "source": [
        "Давайте повторим то же самое но с моделями на биграммах и триграммах. Сравните результаты. Почему они такие?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpnvyDBMns81",
        "outputId": "b20ac62d-c030-4fe9-9e97-169e5daf38b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45.36418524879905\n"
          ]
        }
      ],
      "source": [
        "n = 2\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)\n",
        "\n",
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    value = model.perplexity(test)\n",
        "    all_ppls.append((' '.join(X_test_list[i]), value))\n",
        "    if value != np.inf:\n",
        "        avg_ppl += value\n",
        "print(avg_ppl / i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_34Eyiuns81",
        "outputId": "f807be4a-b260-4d0f-b0a1-5d3525c74e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"`` what ? ''\", 33.18575945912123) (\"there once was a man from nantucket . his dick was so long he could suck it . he said with a grin , as he wiped from his chin , `` if my ear was a cunt i would fuck it . ''\", inf)\n"
          ]
        }
      ],
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrAsJ4o5ns81",
        "outputId": "352ef5ba-3dae-4253-84e9-f3d22143aaab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.915578394055283\n"
          ]
        }
      ],
      "source": [
        "n = 3\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)\n",
        "\n",
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    value = model.perplexity(test)\n",
        "    all_ppls.append((' '.join(X_test_list[i]), value))\n",
        "    if value != np.inf:\n",
        "        avg_ppl += value\n",
        "print(avg_ppl / i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qF1JvzIns82",
        "outputId": "5cedf0bd-d5a1-40f0-fb44-e24389d6a52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"`` what ? ''\", 16.107730324857563) ('oh , snap !', inf)\n"
          ]
        }
      ],
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNXEL9mtns82"
      },
      "source": [
        "И давайте напоследок попробуем сгенерировать последовательность с помощью обученной модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQRzB62tns82",
        "outputId": "28a09e6e-dda3-48e4-ba89-58e0cdd04893"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopped',\n",
              " 'posting',\n",
              " 'youtube',\n",
              " 'videos',\n",
              " 'and',\n",
              " 'doing',\n",
              " 'nothing',\n",
              " '.',\n",
              " 'it',\n",
              " 'sees',\n",
              " 'them',\n",
              " 'all',\n",
              " '?',\n",
              " \"''\",\n",
              " 'says',\n",
              " 'the',\n",
              " 'shopkeeper',\n",
              " 'then',\n",
              " 'recommends',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.generate(20, text_seed=['he'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KQFcyvlthGke"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}