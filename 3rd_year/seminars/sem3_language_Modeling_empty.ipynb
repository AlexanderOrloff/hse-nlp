{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7c0vMPN8gWE"
      },
      "source": [
        "Некоторые задания в этой тетрадки были созданы на основе соотвествующей тетрадки курса NLP от Elena Voita."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pjlNnOv4Ut4"
      },
      "source": [
        "# Генерация текста: н-граммы\n",
        "\n",
        "В этой тетрадке мы научимся делать простую модель генерации текста на основе н-грамм и встречаемости в корпусе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nlpXQYlpuwmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TcWFfFlLgb1r"
      },
      "outputs": [],
      "source": [
        "random.seed(1)\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WT4GhNjvba0"
      },
      "source": [
        "Будем пробовать генерировать шутки. Для обучения будем использовать [датасет с постами reddit](https://kaggle.com/datasets/thedevastator/one-million-reddit-jokes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2VJz6GMP1nNu"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/NLP Course Tutoring/datasets/reddit_jokes.csv'\n",
        "data = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "xDqSNS4s_tXc",
        "outputId": "dd5acba6-f3a0-4137-8f9e-8b36d385e59d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e533f01b-fd61-4548-b28e-456a8356406e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit.id</th>\n",
              "      <th>subreddit.name</th>\n",
              "      <th>subreddit.nsfw</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>permalink</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>selftext</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbp1i</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785543</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbp1i...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My corona is covered with foreskin so it is no...</td>\n",
              "      <td>I am soooo glad I'm not circumcised!</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>post</td>\n",
              "      <td>ftboup</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785522</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftboup...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It's called Google Sheets.</td>\n",
              "      <td>Did you know Google now has a platform for rec...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbopj</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785508</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbopj...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The vacuum doesn't snore after sex.\\r\\n\\r\\n&amp;am...</td>\n",
              "      <td>What is the difference between my wife and my ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbnxh</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785428</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbnxh...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>My last joke for now.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbjpg</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785009</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbjpg...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>The Nintendo 64 turns 18 this week...</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e533f01b-fd61-4548-b28e-456a8356406e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e533f01b-fd61-4548-b28e-456a8356406e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e533f01b-fd61-4548-b28e-456a8356406e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d36f8eb7-51c1-4f34-8fb2-f3447091c3be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d36f8eb7-51c1-4f34-8fb2-f3447091c3be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d36f8eb7-51c1-4f34-8fb2-f3447091c3be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   type      id subreddit.id subreddit.name  subreddit.nsfw  created_utc  \\\n",
              "0  post  ftbp1i        2qh72          jokes           False   1585785543   \n",
              "1  post  ftboup        2qh72          jokes           False   1585785522   \n",
              "2  post  ftbopj        2qh72          jokes           False   1585785508   \n",
              "3  post  ftbnxh        2qh72          jokes           False   1585785428   \n",
              "4  post  ftbjpg        2qh72          jokes           False   1585785009   \n",
              "\n",
              "                                           permalink      domain  url  \\\n",
              "0  https://old.reddit.com/r/Jokes/comments/ftbp1i...  self.jokes  NaN   \n",
              "1  https://old.reddit.com/r/Jokes/comments/ftboup...  self.jokes  NaN   \n",
              "2  https://old.reddit.com/r/Jokes/comments/ftbopj...  self.jokes  NaN   \n",
              "3  https://old.reddit.com/r/Jokes/comments/ftbnxh...  self.jokes  NaN   \n",
              "4  https://old.reddit.com/r/Jokes/comments/ftbjpg...  self.jokes  NaN   \n",
              "\n",
              "                                            selftext  \\\n",
              "0  My corona is covered with foreskin so it is no...   \n",
              "1                         It's called Google Sheets.   \n",
              "2  The vacuum doesn't snore after sex.\\r\\n\\r\\n&am...   \n",
              "3                                          [removed]   \n",
              "4                                          [removed]   \n",
              "\n",
              "                                               title  score  \n",
              "0               I am soooo glad I'm not circumcised!      2  \n",
              "1  Did you know Google now has a platform for rec...      9  \n",
              "2  What is the difference between my wife and my ...     15  \n",
              "3                              My last joke for now.      9  \n",
              "4              The Nintendo 64 turns 18 this week...    134  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSHwGZ-S3t-a"
      },
      "source": [
        "Так как наша задача генерации требует только текста, оставим только соответствующий столбец."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Sg3r3lQI16CR"
      },
      "outputs": [],
      "source": [
        "columns = ['selftext']\n",
        "data = data[columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edTMfW2Z6lBP"
      },
      "source": [
        "## Обработка данных\n",
        "###1. Чистка датасета\n",
        "Для начала нужно определиться, есть в данных пропуски, и избавиться от них, если есть.\n",
        "\n",
        "__Подсказка:__ Часто пропуски они обозначаются как nan, но иногда можно заметить иные способы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IhF_dtcpZ4-F"
      },
      "outputs": [],
      "source": [
        "# <YOUR CODE HERE> #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Z1N5z2Z4-I"
      },
      "source": [
        "Надо тексты привести к нижнему регистру и убрать пунктуацию.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы. При делении текста на слова, используйте word_tokenize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30WZnCmyZ4-I",
        "outputId": "1ea7a2c9-a24d-4c08-b0ab-98739160296b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ3V-peRAg3d"
      },
      "source": [
        "Надо тексты привести к нижнему регистру. Пунктуацию можно оставить, так как она влияет на смысл предложения и на встречаемость.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы. При делении текста на слова, используйте word_tokenize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7BN4LWOLZ4-I"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoPyw7dvZ4-J",
        "outputId": "295210c3-5d1a-49cc-bc33-cef83f6ddbfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from string import punctuation\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zWzU9n0wZ4-J"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    '''\n",
        "    Делит текст на слова и пунктуацию и приводит все к нижнему регистру\n",
        "    :param text: строка\n",
        "    :returns: список слов и знаков препинания\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    new_text = []\n",
        "    for word in word_tokenize(text):\n",
        "        new_text.append(word)\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87tTCnhoZ4-J",
        "outputId": "87f1f59e-6b89-4d9d-bb5b-bd0ca9c6e9f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 494157/494157 [04:26<00:00, 1854.99it/s]\n",
            "100%|██████████| 494157/494157 [00:00<00:00, 828060.89it/s] \n"
          ]
        }
      ],
      "source": [
        "data['words'] = data['selftext'].progress_apply(clean_text)\n",
        "data['lens'] = data['words'].progress_apply(len)\n",
        "data = data[data.lens > 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.sample(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YSTg92TiZ4-J"
      },
      "outputs": [],
      "source": [
        "words = data['words'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDY-l21aZ4-J",
        "outputId": "58782303-c4ed-48be-e158-baf523091aa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['my',\n",
              "  'corona',\n",
              "  'is',\n",
              "  'covered',\n",
              "  'with',\n",
              "  'foreskin',\n",
              "  'so',\n",
              "  'it',\n",
              "  'is',\n",
              "  'not',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'viruses',\n",
              "  '.'],\n",
              " ['it', \"'s\", 'called', 'google', 'sheets', '.']]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUp_9FzUW3Lu"
      },
      "source": [
        "## N-grams\n",
        "Для начала попробуем создать самую простую модель, основанную на встречаемости н-граммы в корпусе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mP00Mb3MlMeL"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQQpVdxSBahu"
      },
      "outputs": [],
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS = '[bos]', '[eos]'\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, lines, n):\n",
        "        assert n >= 1\n",
        "        self.n = n\n",
        "        counts = self.ngram_counts(lines, self.n)\n",
        "\n",
        "        # перевести количества в вероятности\n",
        "        self.probs = defaultdict(Counter)\n",
        "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
        "        # <YOUR CODE HERE> #\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        \"\"\"\n",
        "        :param prefix: строка запроса\n",
        "        :returns: словарь с возможными продолжениями заданного префикса\n",
        "        \"\"\"\n",
        "        prefix = prefix.split()\n",
        "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
        "        prefix = [ BOS ] * (self.n - 1 - len(prefix)) + prefix\n",
        "        return self.probs[tuple(prefix)]\n",
        "\n",
        "    @staticmethod\n",
        "    def ngram_counts(lines: list, n: int) -> dict:\n",
        "        '''\n",
        "        Создаёт словарь, где каждому префиксу (n-1 слово) присваивается словарь,\n",
        "        в котором ключи - слова, а значения - количество н-грамм в текстах\n",
        "        :param lines: список списков\n",
        "        :param n: количество слов в н-грамме\n",
        "        :returns: словарь, в котором для каждого в префикса известно количество\n",
        "        н-грамм с каждым словом\n",
        "        '''\n",
        "        # dictionary[(word1, word2)][word3] = count((word1, word2, word3))\n",
        "        dictionary = defaultdict(Counter)\n",
        "        for line in lines:\n",
        "            new_line = [BOS] * (n-1) + line + [EOS]\n",
        "            for i in range(n-1, len(new_line)):\n",
        "                prefix = tuple(new_line[i-n+1:i])\n",
        "                word = new_line[i]\n",
        "                dictionary[prefix][word] += 1\n",
        "        return dictionary\n",
        "\n",
        "# Проверим работу функции ngram_counts\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = NGramLanguageModel.ngram_counts(dummy_lines, n=3)\n",
        "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "assert len(dummy_counts[(BOS, BOS)]) == 66\n",
        "assert dummy_counts[BOS, 'a']['melon'] == 1\n",
        "\n",
        "# Проверим работу модели\n",
        "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
        "p_initial = dummy_lm.get_possible_next_tokens('')\n",
        "assert p_initial.most_common(1)[0][0] == 'a'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v96is9vGawaV"
      },
      "source": [
        "1. Попробуем составить предложение используя жадный метод."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p4C8r0TP-jj"
      },
      "outputs": [],
      "source": [
        "def get_next_word(lm: NGramLanguageModel, prefix: str) -> str:\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    # <YOUR CODE HERE> #\n",
        "    return # next word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcIeQluWfJ-f"
      },
      "outputs": [],
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh9oYWyosfnG"
      },
      "outputs": [],
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, prefix)\n",
        "while word != EOS:\n",
        "    prefix += f' {word}'\n",
        "    word = get_next_word(lm, prefix)\n",
        "\n",
        "print(prefix + f'{word} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euWO6e9hTRkG"
      },
      "source": [
        "2. Выбор наиболее вероятного слова не показал хороших результатов. Тем более, он будет строить очень много похожих предложений, а нам хочется разнообразия. Давайте попробуем семплировать методом top-k: выбираем k наиболее встречаемых вариантов и из них выбираем один случайным образом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlQNWIZrS-aK"
      },
      "outputs": [],
      "source": [
        "def get_next_word(lm: NGramLanguageModel, prefix: str, k:int) -> str:\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :param k: количество слов в top-k\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    # <YOUR CODE HERE> #\n",
        "    return # next word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUlsfNObToqk"
      },
      "outputs": [],
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for i in range(repeat):\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkBhxv88Ts0_"
      },
      "outputs": [],
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, '', 5)\n",
        "while word != EOS:\n",
        "    prefix += f'{word} '\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "print(prefix + f'{word} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC5axKpqtcvH"
      },
      "source": [
        "3. Для сравнения можно сделать beam search. Напоминаем, что он на каждом шаге выбирает k наилучших вариантов - те, с которыми наибольшая вероятность всего предложения. Кроме этого надо не забыть, что мы переводим вероятности в логарифмы: таким образом считается сумма логарифмов вероятностей для каждой н-граммы, из которого состоит предложение.\n",
        "Чтобы не пересчитывать каждый раз корпус, давайте будем считать вероятность последней н-граммы.\n",
        "\n",
        "![picture](https://d2l.ai/_images/beam-search.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3ceW1U7GPlA"
      },
      "source": [
        "\\begin{align}\n",
        "        \\frac{1}{L^\\alpha}\\sum_{t'=1}^LlogP(y_{t'}|y_{t'-n}, ..., y_{t'-1})\n",
        "    \\end{align}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D71N55ESiJav"
      },
      "source": [
        "## Оценивание модели\n",
        "Раз мы научились делать простую языковую модель, надо понять, насколько она хорошо описывает язык. Для оценивания этого используем перплексию.\n",
        "\n",
        "$PPL(W) = e^{ln(P(W)^{-\\frac{1}{N}})} =e^{{-\\frac{1}{N}}ln(P(W))}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vos4iA5mofJO"
      },
      "source": [
        "1. Для начала нужно разделить данные на тренировочные и тестовые"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtnXGWswob2l"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(data['words'].sample(100000), train_size=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HDDyuiPonKy"
      },
      "source": [
        "2. Давайте напишем функцию, которая будет считать перплексию для каждого отдельного предложения на основе n-грамм. Для каждой нграммы считается её вероятность. Нам её считать не надо, так как она уже записана в атрибуте _self.probs_ в нашем классе модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYUka8tVoqZU"
      },
      "outputs": [],
      "source": [
        "def perplexity(model: NGramLanguageModel, text: list, n=1) -> float:\n",
        "    \"\"\"\n",
        "    :param model: language model\n",
        "    :param text: список н-грамм предложения\n",
        "    :param n: количество слов в н-грамме\n",
        "    :returns: значение перплексии одного предложения\n",
        "    \"\"\"\n",
        "    result = 0\n",
        "    length = 0\n",
        "    # ngram: (word1, word2, word3) if n==3\n",
        "    for ngram in text:\n",
        "        if n == 1:\n",
        "            prefix = ()\n",
        "        else:\n",
        "            prefix = ngram[:n-1]\n",
        "        prob = model.probs[prefix][ngram[-1]]\n",
        "        # <YOUR CODE HERE> #\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtiVA2fWqAri"
      },
      "source": [
        "3. Теперь можем посчитать среднюю перплексию по всему датасету."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nbtX8nbqA_U"
      },
      "outputs": [],
      "source": [
        "n = 1\n",
        "lm = NGramLanguageModel(X_train, n=n)\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=n))\n",
        "    value = perplexity(lm, test_sent, n=n)\n",
        "    avg_ppl += value\n",
        "\n",
        "avg_ppl /=  len(X_test)\n",
        "# assert np.isclose(avg_ppl, 1857.90, atol=1e-1)\n",
        "print(avg_ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnNeiymmI0Yh"
      },
      "source": [
        "Попробуем теперь сравнить перплексию для моделей униграм, биграм и триграм. Почему результаты получились такие?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGhyfsiaJiLr"
      },
      "outputs": [],
      "source": [
        "lm = NGramLanguageModel(X_train, n=2)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=2))\n",
        "    value = perplexity(lm, test_sent, 2)\n",
        "    all_ppls.append((' '.join(sentence), value))\n",
        "    avg_ppl += value\n",
        "print(avg_ppl / len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLM83ZdUWkk5"
      },
      "outputs": [],
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGo7uPzCWlvZ"
      },
      "outputs": [],
      "source": [
        "lm = NGramLanguageModel(X_train, n=3)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=3))\n",
        "    value = perplexity(lm, test_sent, 3)\n",
        "    all_ppls.append((' '.join(sentence), value))\n",
        "    avg_ppl += value\n",
        "print(avg_ppl / len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZVFT-7cWnNg"
      },
      "outputs": [],
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huzgWYb7nmlx"
      },
      "source": [
        "## Использование готовых инструментов\n",
        "К счастью, нам всё писать необязательно. Необходимые функции и модули уже были написаны умными программистами. Давайте посмотрим на модуль nltk и на то, что он нам предлагает."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8OKwq9ql94P"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "\n",
        "n = 1\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J32Wf2Km6Ew"
      },
      "outputs": [],
      "source": [
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    # <YOUR CODE HERE> #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psvTMTHfnUMX"
      },
      "source": [
        "Давайте повторим то же самое но с моделями на биграммах и триграммах. Сравните результаты. Почему они такие?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otWeiZuMneYd"
      },
      "outputs": [],
      "source": [
        "# <YOUR CODE HERE> #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ln4Th3ZKUiF"
      },
      "source": [
        "И давайте напоследок попробуем сгенерировать последовательность с помощью обученной модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2_FOjwAKbW1"
      },
      "outputs": [],
      "source": [
        "model.generate(20, text_seed=['he'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCm30Mgf56Cj"
      },
      "source": [
        "--------------"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
