{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrBqbGyxJN67"
      },
      "outputs": [],
      "source": [
        "!pip install natasha slovnet navec -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Готовые инструменты для решения различных задач\n",
        "\n",
        "До этого момента обычно мы пользовались разными библиотеками для решения наших задач: сегментация предложения и деление на токены - nltk, лемматизация и работа с морфологией - mystem или pymorphy, работа с синтаксисом - udpipe и тд. Но работа с разными библиотеками может вызывать трудности: различия в подходах, в формате ввода и вывода данных. Может сделать одну библиотеку для решения всех задач? Так и была придумана она - natasha.\n",
        "\n",
        "Что она умеет:\n",
        "- сегментация текста на предложения/токены\n",
        "- морфологический анализ\n",
        "- синтаксический анализ\n",
        "- поиск именнованных сущностей\n",
        "- создание собственных грамматик и правил\n",
        "- использование предобученных эмбеддингов"
      ],
      "metadata": {
        "id": "awEEaakmNr7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "\n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "\n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "\n",
        "    Doc\n",
        ")\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "_WZ1kEj7KRG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем выбрать те элементы, которые нужны именно нам для решения задачи. Для начала их нужно инициализировать: сегментатор для деления на токены, морфологический и синтаксический парсеры, тэггер для NER.\n",
        "\n",
        "Все теггеры основаны на предобученных эмбеддингах из класса NewsEmbedding - это обученный на русских новостях Glove."
      ],
      "metadata": {
        "id": "k7XiBWu0Vgr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natasha как таковая"
      ],
      "metadata": {
        "id": "_9lMVqKvcQhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "segmenter = Segmenter()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "\n",
        "morph_vocab = MorphVocab()\n",
        "names_extractor = NamesExtractor(morph_vocab)"
      ],
      "metadata": {
        "id": "YoZ3shtLKhYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объект класса Doc - это что-то типа скрытого пайплайна: мы ему говорим, какие этапы ему нужно пройти."
      ],
      "metadata": {
        "id": "8UAO_RjHap-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'У моего любимого певца Егора Крида вышел новый трек. Буду его слушать весь день!'\n",
        "doc = Doc(text)\n",
        "\n",
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)\n",
        "doc.parse_syntax(syntax_parser)"
      ],
      "metadata": {
        "id": "3ctRhYyOVZHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Некоторые этапы не работают без предыдущих."
      ],
      "metadata": {
        "id": "e0S18FrBiIpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'У моего любимого певца Егора Крида вышел новый трек. Буду его слушать весь день!'\n",
        "doc = Doc(text)\n",
        "\n",
        "try:\n",
        "    morph = doc.tag_morph(morph_tagger)\n",
        "except Exception as err:\n",
        "    print('Проблема:', err)"
      ],
      "metadata": {
        "id": "jJGDmOb_iI6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Сегментация"
      ],
      "metadata": {
        "id": "myvC4JLRjPlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc.tokens[:5])\n",
        "print(doc.sents[:5])"
      ],
      "metadata": {
        "id": "S73-QVxTjPHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(doc.sents):\n",
        "    print(\"\\n-- Sentence %d --\" % i)\n",
        "    for t in s.tokens:\n",
        "        print(t.text, t.pos, sep=\"\\t\")"
      ],
      "metadata": {
        "id": "-_8y6kR-kHc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Лемматизация"
      ],
      "metadata": {
        "id": "moh7xwJQjY49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно лемматизировать просто тексты:"
      ],
      "metadata": {
        "id": "WwNFmjPqlmP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "\n",
        "{_.text: _.lemma for _ in doc.tokens}"
      ],
      "metadata": {
        "id": "qXMP4KwMjam8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "А можно лемматизировать сущности, которым часто требуется другая обработка:"
      ],
      "metadata": {
        "id": "MkJzoTZMloG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc.tag_ner(ner_tagger)\n",
        "for span in doc.spans:\n",
        "    span.normalize(morph_vocab)\n",
        "\n",
        "{_.text: _.normal for _ in doc.spans}"
      ],
      "metadata": {
        "id": "pYEqaUdDkszL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Задание 1:__ Как думаете, какие ещё сущности natasha умеет находить? Придумайте свои примеры, в которых находятся эти сущности."
      ],
      "metadata": {
        "id": "KlSHNkOcLM6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Задание 1 ###\n",
        "### Your code here ###"
      ],
      "metadata": {
        "id": "ZgWjdxDkQJTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Задание 2:__ Придумайте такой пример, в котором есть какая-то сущность, которая неверно лемматизируется с помощью token.lemmatize, но в span.normalize верно"
      ],
      "metadata": {
        "id": "1YDmML1rRYbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Задание 2 ###\n",
        "### Your code here ###"
      ],
      "metadata": {
        "id": "TWFcWIGvQMfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Морфология"
      ],
      "metadata": {
        "id": "sD2ApSMTcUtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'У моего любимого певца Егора Крида вышел новый трек. Буду его слушать весь день!'\n",
        "doc = Doc(text)\n",
        "\n",
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)\n",
        "doc.parse_syntax(syntax_parser)"
      ],
      "metadata": {
        "id": "3-x2xnjXRt02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = doc.sents[0]\n",
        "sent.morph.print()"
      ],
      "metadata": {
        "id": "d7XL_QZdVasw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent.morph.tokens[:2]"
      ],
      "metadata": {
        "id": "6br7krjab9ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Синтаксис"
      ],
      "metadata": {
        "id": "a41BH70zcWg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent.syntax.print()"
      ],
      "metadata": {
        "id": "tjMuI2IBVcxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent.syntax.tokens[:2]"
      ],
      "metadata": {
        "id": "R8Q_jkYhc5OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NER"
      ],
      "metadata": {
        "id": "g47KWmUvcYif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_tagger = NewsNERTagger(emb)\n",
        "doc.tag_ner(ner_tagger)\n",
        "doc.ner.print()"
      ],
      "metadata": {
        "id": "mgW6ZJVScC7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc.ner"
      ],
      "metadata": {
        "id": "YelRu6I4c8yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Но на самом деле Natasha - это обертка для более маленьких библиотек, каждая из которых отвечает за что-то своё."
      ],
      "metadata": {
        "id": "r5m4q4AVnZX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Razdel\n",
        "По сути это библиотека-токенизатор. Она построена на правилах, основнанных на стандартах русской письменной речи."
      ],
      "metadata": {
        "id": "r0r3_VyHnhO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize, sentenize\n",
        "# сравним с nltk\n",
        "from nltk import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "cXg2Uewzn0k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Разве это правильно? Написано 0,5л, а вы приносите 0,45л, за те же деньги'\n",
        "list(tokenize(text))"
      ],
      "metadata": {
        "id": "nkTA6W5wnkCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(text)"
      ],
      "metadata": {
        "id": "ev_uoiI6ox_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Одна из полезных штук здесь - это получение индексов начала и конца токена. Для чего это может быть нужно?"
      ],
      "metadata": {
        "id": "yvmKg7ApjokG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Кто вообще в 21 веке пользуется pymorphy или natasha, если есть гпт?\n",
        "Я с ним все домашки делаю и нормально.\n",
        "'''\n",
        "list(sentenize(text))"
      ],
      "metadata": {
        "id": "4JGYtja2VzjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(text)"
      ],
      "metadata": {
        "id": "3VQLlKqdV0sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Задание 3:__ Как думаете, какие тексты обычно вызывают затруднения при делении на предложения? Попробуйте привести пример такого небольшого текста, чтобы razdel и nltk по-разному его разделили\n",
        "\n"
      ],
      "metadata": {
        "id": "PtTaVvBHXHXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = # your text here\n",
        "list(sentenize(text))"
      ],
      "metadata": {
        "id": "2DeIiayHnyoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(text)"
      ],
      "metadata": {
        "id": "8vNsYY8gov-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!НО! razdel хорошо работает только с качественно написанными текстами:("
      ],
      "metadata": {
        "id": "azAfdVsjvK_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Мама купила платье. оно красивое.'\n",
        "list(sentenize(text))"
      ],
      "metadata": {
        "id": "3qZi2_PavKsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(text)"
      ],
      "metadata": {
        "id": "neaXNLWYvSX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slovnet"
      ],
      "metadata": {
        "id": "50ddVw8BbdLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.yandexcloud.net/natasha-slovnet/packs/slovnet_ner_news_v1.tar\n",
        "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IieMH_u5L8dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Slovnet__](https://habr.com/ru/articles/516098/#slovnet) - библиотека с моделями для решения NER задач, а также морфологического и синтаксического парсинга. Отличия от подходов с использованием нейросетей типа Bert - скорость и маленький вес модели. В качестве входных данных использует предобученные эмбеддинги navec.\n",
        "\n",
        "Проблема: опять же работает на качественных данных, типа художественной литературы и новостей, так как не решает проблему OOV. Если слово не находится в словаре, то заменяется на \"\\<unk\\>\""
      ],
      "metadata": {
        "id": "Oo8fLbcOgdqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import navec\n",
        "\n",
        "from navec import Navec\n",
        "from slovnet import NER\n",
        "from ipymarkup import show_span_ascii_markup as show_markup\n",
        "\n",
        "# path_navec = 'navec_hudlit_v1_12B_500K_300d_100q.tar\n",
        "\n",
        "path_navec = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
        "navec = Navec.load(path_navec)\n",
        "path_slovnet = 'slovnet_ner_news_v1.tar'\n",
        "ner = NER.load(path_slovnet)\n",
        "ner.navec(navec)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iRmQLCzbKnG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'У моего любимого певца Егора Крида вышел новый трек. Буду его слушать весь день!'\n",
        "\n",
        "markup = ner(text)\n",
        "show_markup(markup.text, markup.spans)"
      ],
      "metadata": {
        "id": "ig6JTygfT9xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yargy - Поиск имён, дат и адресов"
      ],
      "metadata": {
        "id": "dHmlD-bKm88Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если много однотипных данных, которые можно описать правилами, то использовать сложный NER, тратить время на разметку и обучение необязательно. Yargy - система описательных правил, что-то типа умных регулярок, только быстрее и удобнее. Помимо этого, они ещё приводят всё к одному виду - его в целом тоже можно придумать самим.\n",
        "\n",
        "Есть некоторые уже готовые правила:"
      ],
      "metadata": {
        "id": "fXqYZVVB3vOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import (\n",
        "    NamesExtractor,\n",
        "    DatesExtractor,\n",
        "    MoneyExtractor,\n",
        "    AddrExtractor\n",
        ")\n",
        "\n",
        "names_extractor = NamesExtractor(morph_vocab)\n",
        "dates_extractor = DatesExtractor(morph_vocab)\n",
        "money_extractor = MoneyExtractor(morph_vocab)\n",
        "addr_extractor = AddrExtractor(morph_vocab)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fclAW61om990"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Даты"
      ],
      "metadata": {
        "id": "UyUsODPR47Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '24.01.2017, 2015 год, 2014 г, 1 апреля, май 2017 г., 9 мая 2017 года'\n",
        "matches = list(dates_extractor(text))"
      ],
      "metadata": {
        "id": "G2KbocWK4JGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches[:2]"
      ],
      "metadata": {
        "id": "7Gjy2b0C7xa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for date in matches:\n",
        "    day, month, year = date.fact.day, date.fact.month, date.fact.year\n",
        "    print(f'{day}.{month}.{year}')"
      ],
      "metadata": {
        "id": "TpnEpEZ-7t5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Имена"
      ],
      "metadata": {
        "id": "w1K2F-RA48OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Меня зовут Ксюша Шерман. Или Шерман Ксюша. Или даже Ксения Валерьевна Шерман'\n",
        "list(names_extractor(text))"
      ],
      "metadata": {
        "id": "-TW29AvN4kHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Но почему-то его иногда клинит"
      ],
      "metadata": {
        "id": "_c1ePZuZbo9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'а может и не Ксюша'\n",
        "list(names_extractor(text))"
      ],
      "metadata": {
        "id": "i9j9Z2yp4o5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Адреса"
      ],
      "metadata": {
        "id": "9XH0jqFP5OtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Я живу в г.Москве, на ул. Академическая'\n",
        "list(addr_extractor(text))"
      ],
      "metadata": {
        "id": "GREyuLUD5C5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Задание 4:__ Снова ваша очередь придумать такой адрес, который ему нормально не удастся распарсить."
      ],
      "metadata": {
        "id": "HaSg3BLzcJ8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = # your text here\n",
        "list(addr_extractor(text))"
      ],
      "metadata": {
        "id": "-QpYTCmy5p8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Денежные выражения"
      ],
      "metadata": {
        "id": "VgR7xGd56aHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'у меня есть 250р.'\n",
        "list(money_extractor(text))"
      ],
      "metadata": {
        "id": "4_CrpWrf51Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'у меня есть 250 тысяч рублей'\n",
        "list(money_extractor(text))"
      ],
      "metadata": {
        "id": "chVYE-lX6lDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'у меня есть 250 тенге'\n",
        "list(money_extractor(text))"
      ],
      "metadata": {
        "id": "DUn90igz6o6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно так же придумать свои правила. Есть достаточно понятные описания от создателей библиотеки.\n",
        "Стоит помнить, что готовые правила работают, опять же, с качественными данными типа новостей или юридических документов (что, кстати, является одной из популярных задач)."
      ],
      "metadata": {
        "id": "_jFLxL_962Fb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy"
      ],
      "metadata": {
        "id": "gGQyKQtQ7NQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy -q\n",
        "!python -m spacy download ru_core_news_sm -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bZG2IR6o7EHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Загружаем весь пайплайн для русского\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "\n",
        "# Обрабатываем текст\n",
        "text = 'У моего любимого певца Егора Крида вышел новый трек. Буду его слушать весь день!'\n",
        "doc_spacy = nlp(text)\n",
        "\n",
        "# Выведем токены, леммы и теги\n",
        "for i, s in enumerate(doc_spacy.sents):\n",
        "    print(\"\\n-- Sentence %d --\" % i)\n",
        "    for t in s:\n",
        "        print(t.text, t.pos_, t.dep_)"
      ],
      "metadata": {
        "id": "537DeD0y8YpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'У моего любимого певца Егора Крида вышел новый трек. Буду его слушать весь день!'\n",
        "doc_natasha = Doc(text)\n",
        "\n",
        "doc_natasha.segment(segmenter)\n",
        "doc_natasha.tag_morph(morph_tagger)\n",
        "doc_natasha.parse_syntax(syntax_parser)\n",
        "\n",
        "for i, s in enumerate(doc_natasha.sents):\n",
        "    print(\"\\n-- Sentence %d --\" % i)\n",
        "    for t in s.tokens:\n",
        "        print(t.text, t.pos, t.rel, sep=\"\\t\")"
      ],
      "metadata": {
        "id": "ULMCMiXejxnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ Проанализируйте результаты. Почему они могут быть такие?"
      ],
      "metadata": {
        "id": "6aJSZIwblU3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лемматизация"
      ],
      "metadata": {
        "id": "HU7lcVEAonO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(doc_spacy.sents):\n",
        "    print(\"\\n-- Sentence %d --\" % i)\n",
        "    for t in s:\n",
        "        print(t.text, t.lemma_, t.lemma, sep=\"\\t\")"
      ],
      "metadata": {
        "id": "NMwaK7scncp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Морфология"
      ],
      "metadata": {
        "id": "N4VbT1zspN8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(doc_spacy.sents):\n",
        "    print(\"\\n-- Sentence %d --\" % i)\n",
        "    for t in s:\n",
        "        print(t.text, t.morph)"
      ],
      "metadata": {
        "id": "thFmdXtboMqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Синтаксис"
      ],
      "metadata": {
        "id": "vPqD7d4qpTUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc_spacy:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "id": "pwZYjLCQpV1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Вопрос:__ А что такое \"xxxx\" и подобное в выводе?"
      ],
      "metadata": {
        "id": "vuf5fT1cdlw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.serve(doc_spacy, style=\"dep\")"
      ],
      "metadata": {
        "id": "ILm1-Pz_o6z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.serve(doc_spacy, style=\"ent\")"
      ],
      "metadata": {
        "id": "Rud_pyYNp-F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc_spacy:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "            [child for child in token.children])"
      ],
      "metadata": {
        "id": "lIwDW_5fx-Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Задание 5:__ Выберите любую понравившуюся библиотеку - natasha или spacy и попробуйте достать все пары \"прилагательное+существительное\" из предложения:"
      ],
      "metadata": {
        "id": "tYisWDqTqF6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'У моего любимого певца Егора Крида вышел новый трек. Буду его слушать весь день сегодняшний!'\n",
        "\n",
        "# YOUR CODE HERE #"
      ],
      "metadata": {
        "id": "j2pF9zDmx-zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0wQvtC3qJmA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}