{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYLglZE2QIEF"
   },
   "source": [
    "## Opinion Mining/ Selenium\n",
    "\n",
    "Постепенно подбираемся к теме Sentiment Analysis.\n",
    "\n",
    "Для начала будем считать, что у текста есть\n",
    "- полярность / polarity - является ли текст эмоционально окрашенным\n",
    "- тональность / sentiment - как текст оценивает некий объект по шкале -1...1 / 0...1 / 1...5 и тд\n",
    "\n",
    "Полезные источники данных:\n",
    "- сайты отзывов / сайты интернет-магазинов (товары) - Amazon ....\n",
    "- сайты с медиаконтентом - Youtube, Instagram ...\n",
    "- специализированные сайты - Кинопоиск, IMDB, ...\n",
    "\n",
    "Как скачивать оттуда данные?\n",
    "\n",
    "- requests + fake_useragent\n",
    "- Selenium \n",
    "  - возможность взаимодействия с элементами (кнопки, скролл и тп)\n",
    "  - обходит капчу, тк имитирует браузер\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0rDcUxOPalR"
   },
   "source": [
    "Как запустить на своем компьютере:\n",
    "\n",
    "1. Для начала нужно скачать chromedriver (https://chromedriver.chromium.org/downloads) в рабочую папку: у вас появится архив с бинарным файлом внутри. Архив нужно будет распаковать, а путь к папке добавить в path. Можно пользоваться драйверами различных браузеров, здесь я оставляю ссылки на версию google chrome.\n",
    "2. В начале скрипта мы создаем какую-либо переменную, в которую помещаем наш браузер.\n",
    "Пр.: driver = webdriver.Chrome(<полный путь к бинарному файлу>)\n",
    "3. Открыть страницу можно с помощью функции get. \n",
    "Прокрутить страницу можно с помощью кода внизу.\n",
    "4. Находить различные элементы страницы можно с помощью ряда функций find_elements_by_<...> (см. документацию).\n",
    "Чтобы понять, как найти какой-либо элемент на странице, нужно в веб-инспекторе в браузере посмотреть путь элемента. В гугл-хроме это можно сделать, например, так: Посмотреть -> Разработчикам -> Проверить элементы -> Навести стрелкой на нужный элемент.\n",
    "5. Как только мы нашли нужный элемент, можно на него кликнуть функцией .click() или посмотреть текст функцией .text().\n",
    "6. В конце программы нужно  закрыть, если открывалли как сверху и, конечно, как -то сохранить ваши данные\n",
    "\n",
    "Подробнее: https://towardsdatascience.com/how-to-scrape-youtube-comments-with-python-61ff197115d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ72KiPqMQyJ",
    "outputId": "b1e28178-bb5e-45a2-f86a-9eebf99d48bc"
   },
   "outputs": [],
   "source": [
    "!pip3 install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKISQiFeT8GW"
   },
   "source": [
    "## Данные\n",
    "\n",
    "Возьмем противоречивое видео с ютьюба и попробуем проанализировать комментарии к нему\n",
    " https://www.youtube.com/watch?v=kuhhT_cBtFU&t=2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "uB07GEs6Mmlc",
    "outputId": "a507724e-f125-48fd-a938-541c98fe677b"
   },
   "source": [
    "## Тетрадка для подготовки данных \n",
    "[в Colab](https://colab.research.google.com/drive/1IFyhNz3UCvIEgHjskLNIgD0UddvxCkPw?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob stanza spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем модель для SpaCy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWvURK7tyBcU",
    "outputId": "98a343a6-52ce-4bbb-a592-ecbc32b09082"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import stanza\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stanza.download(\"en\")\n",
    "stanza_nlp = stanza.Pipeline(\"en\", processors=\"tokenize,lemma,pos,sentiment\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "# Очистка текстов\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('@', '', text)\n",
    "    text = re.sub('\\[.*?\\]', ' ', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', ' ', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vU-C_-QxlQ5"
   },
   "outputs": [],
   "source": [
    "def lemmatize(text):  # spacy\n",
    "    doc = spacy_nlp(text)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "def lemmatize_stanza(text):  #stanza\n",
    "    doc = stanza_nlp(text)\n",
    "    return [word.lemma for sent in doc.sentences for word in sent.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSIlCQMoxKWu"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    return [t for t in tokens if t not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipelinize(texts):\n",
    "    return spacy_nlp.pipe(texts, disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7B1A9VMTxvL7"
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('youtube_comments.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJlTPzyszxQG"
   },
   "outputs": [],
   "source": [
    "a['clean_text'] = a['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "Z56n9sXexo1C",
    "outputId": "7781e0e3-c19e-44fa-d851-eba15fcadd3b"
   },
   "outputs": [],
   "source": [
    "a.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = a.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_comments = []\n",
    "for doc in pipelinize(sample_texts['clean_text'].to_list()):\n",
    "    lemmas_comments.append([token.lemma_ for token in doc])\n",
    "sample_texts['lem'] = lemmas_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECgzv6_80klm",
    "outputId": "704ebc68-c7df-4a18-c74c-51f4575211fa"
   },
   "outputs": [],
   "source": [
    "sample_texts['best'] = sample_texts['lem'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "s3APqrQG1r6N",
    "outputId": "97c0518a-02c3-4261-e894-c4a0b2de47c4"
   },
   "outputs": [],
   "source": [
    "sample_texts.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgZua0qdIS5M"
   },
   "source": [
    "## Предварительный статистический анализ\n",
    "\n",
    "Как предварительно проанализировать данные, чтобы понимать, куда копать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на распределение частот лемм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "H_v_UAW9ISFp",
    "outputId": "11aebb94-784b-46c6-db09-3643340a6a57"
   },
   "outputs": [],
   "source": [
    "#Your code here - freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на частоты биграмм и триграмм:\n",
    "- `nltk.bigrams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Rmi6g-iIvBS"
   },
   "outputs": [],
   "source": [
    "#bigram freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsfscXzPIwdT"
   },
   "outputs": [],
   "source": [
    "#trigram freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А если убрать слишком короткие комментарии?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTjBrZqqJ3tq"
   },
   "source": [
    "## TextBlob\n",
    "\n",
    "Простая библиотека, которая совмещает статистические методы и regexp-паттерны.\n",
    "\n",
    "The sentiment property returns a namedtuple of the form `Sentiment(polarity, subjectivity)`. \n",
    "\n",
    "The polarity score is a float within the range [-1.0, 1.0]. \n",
    "\n",
    "The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4geiVQkzJL7I",
    "outputId": "0f9ab7f6-d967-4cc0-89e4-313dd9f3f248"
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(sample_texts['text'][311276])\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.sentiment_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "hQvogslrJ1Ua",
    "outputId": "cfec4ec9-3b38-4fd4-cdaa-5833d743ac3d"
   },
   "outputs": [],
   "source": [
    "def comment_sentiment(comment):\n",
    "    blob = TextBlob(comment)\n",
    "    return np.mean([s.sentiment.polarity for s in blob.sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts['sent'] = sample_texts['text'].apply(lambda x: comment_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts['sent'].plot.hist(color='salmon', title='Comments Polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts[sample_texts['sent']<-0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHdTl7hTKlrZ"
   },
   "source": [
    "## Stanza Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_sentiment = ['negative', 'neutral', 'positive']\n",
    "for sentence in stanza_nlp(sample_texts['clean_text'][294519]).sentences:\n",
    "    print(stanza_sentiment[sentence.sentiment])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Opinion mining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
